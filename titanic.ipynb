{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def put_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 19\n        else:\n            return 24\n    else:\n        return Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class1male = int(train_data[(train_data[\"Pclass\"]==1) & (train_data[\"Sex\"]==\"male\")][\"Age\"].mean())\nclass2male = int(train_data[(train_data[\"Pclass\"]==2) & (train_data[\"Sex\"]==\"male\")][\"Age\"].mean())\nclass3male = int(train_data[(train_data[\"Pclass\"]==3) & (train_data[\"Sex\"]==\"male\")][\"Age\"].mean())\n\nclass1female = int(train_data[(train_data[\"Pclass\"]==1) & (train_data[\"Sex\"]==\"female\")][\"Age\"].mean())\nclass2female = int(train_data[(train_data[\"Pclass\"]==2) & (train_data[\"Sex\"]==\"female\")][\"Age\"].mean())\nclass3female = int(train_data[(train_data[\"Pclass\"]==3) & (train_data[\"Sex\"]==\"female\")][\"Age\"].mean())\ndef set_age(cols):\n    pclass = cols[0]\n    sex = cols[1]\n    age = cols[2]\n    if pd.isnull(age):\n        if pclass == 1:\n            if sex == \"male\":\n                return class1male\n            else:\n                return class1female\n        elif pclass == 2:\n            if sex == \"male\":\n                return class2male\n            else:\n                return class2female\n        else:\n            if sex == \"male\":\n                return class3male\n            else:\n                return class3female\n    else:\n        return age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data[\"Age\"] = train_data[[\"Pclass\", \"Sex\", \"Age\"]].apply(set_age, axis=1)\n# test_data[\"Age\"] = test_data[[\"Pclass\", \"Sex\", \"Age\"]].apply(set_age, axis=1)\n\ntrain_data[\"Age\"] = train_data[[\"Age\", \"Pclass\"]].apply(put_age, axis=1)\ntest_data[\"Age\"] = test_data[[\"Age\", \"Pclass\"]].apply(put_age, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Cabin\", axis=1, inplace=True)\ntest_data.drop(\"Cabin\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"Embarked\"] = train_data[\"Embarked\"].apply(lambda x: \"S\" if pd.isnull(x) else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fare = int(train_data[(train_data[\"Pclass\"]==3) & (train_data[\"Sex\"]==\"male\")][\"Fare\"].mean())\ntest_data[\"Fare\"] = test_data[\"Fare\"].apply(lambda x: fare if pd.isnull(x) else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Title'] = train_data[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntrain_data[\"Title\"].value_counts()\ntest_data['Title'] = test_data[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_data[\"Title\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Ms', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\ntrain_data['Title'] = train_data['Title'].replace('Major', 'Military')\ntrain_data['Title'] = train_data['Title'].replace('Col', 'Military')\ntrain_data['Title'] = train_data['Title'].replace('Capt', 'Military')\ntrain_data['Title'] = train_data['Title'].replace('Lady', 'Royal')\ntrain_data['Title'] = train_data['Title'].replace('Don', 'Royal')\ntrain_data['Title'] = train_data['Title'].replace('Countess', 'Royal')\ntrain_data['Title'] = train_data['Title'].replace('Jonkheer', 'Royal')\ntrain_data['Title'] = train_data['Title'].replace('Sir', 'Royal')\ntrain_data['Title'] = train_data['Title'].replace('Dona', 'Royal')\ntrain_data[\"Title\"].value_counts()\n\ntest_data['Title'] = test_data['Title'].replace('Mlle', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Ms', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Mme', 'Mrs')\ntest_data['Title'] = test_data['Title'].replace('Major', 'Military')\ntest_data['Title'] = test_data['Title'].replace('Col', 'Military')\ntest_data['Title'] = test_data['Title'].replace('Capt', 'Military')\ntest_data['Title'] = test_data['Title'].replace('Lady', 'Royal')\ntest_data['Title'] = test_data['Title'].replace('Don', 'Royal')\ntest_data['Title'] = test_data['Title'].replace('Countess', 'Royal')\ntest_data['Title'] = test_data['Title'].replace('Jonkheer', 'Royal')\ntest_data['Title'] = test_data['Title'].replace('Sir', 'Royal')\ntest_data['Title'] = test_data['Title'].replace('Dona', 'Royal')\ntest_data[\"Title\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic=pd.concat([train_data, test_data], sort=False)\nlen_train=train_data.shape[0]\ntitanic['LastName'] = titanic[\"Name\"].apply(lambda x: x.split(',')[0].strip())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sex = pd.get_dummies(train_data[\"Sex\"], drop_first=True)\n# embark = pd.get_dummies(train_data[\"Embarked\"], drop_first=True)\n# pclass = pd.get_dummies(train_data[\"Pclass\"], drop_first=True)\n# title = pd.get_dummies(train_data[\"Title\"], drop_first=True)\n# last = pd.get_dummies(train_data[\"LastName\"], drop_first=True)\n# train_data = pd.concat([train_data, sex, embark, pclass, title, last], axis=1)\n\n# train_data.drop([\"PassengerId\", \"Sex\", \"Embarked\", \"Name\", \"Ticket\", \"Pclass\", \"Title\", \"LastName\"], axis=1, inplace=True)\n\n# sex = pd.get_dummies(test_data[\"Sex\"], drop_first=True)\n# embark = pd.get_dummies(test_data[\"Embarked\"], drop_first=True)\n# pclass = pd.get_dummies(test_data[\"Pclass\"], drop_first=True)\n# title = pd.get_dummies(test_data[\"Title\"], drop_first=True)\n# last = pd.get_dummies(test_data[\"LastName\"], drop_first=True)\n# test_data = pd.concat([test_data, sex, embark, pclass, title, last], axis=1)\n\n# test_data.drop([\"PassengerId\", \"Sex\", \"Embarked\", \"Name\", \"Ticket\", \"Pclass\", \"Title\", \"LastName\"], axis=1, inplace=True)\n\nsex = pd.get_dummies(titanic[\"Sex\"], drop_first=True)\nembark = pd.get_dummies(titanic[\"Embarked\"], drop_first=True)\npclass = pd.get_dummies(titanic[\"Pclass\"], drop_first=True)\ntitle = pd.get_dummies(titanic[\"Title\"], drop_first=True)\nlast = pd.get_dummies(titanic[\"LastName\"], drop_first=True)\ntitanic = pd.concat([titanic, sex, embark, pclass, title, last], axis=1)\n\ntitanic.drop([\"PassengerId\", \"Sex\", \"Embarked\", \"Name\", \"Ticket\", \"Pclass\", \"Title\", \"LastName\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = titanic[:len_train]\ntest_data = titanic[len_train:]\ntrain_data[\"Survived\"] = train_data[\"Survived\"].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def has_family(data):\n#     if data[0] > 0 or data[1] > 0:\n#         return 1\n#     else:\n#         return 0\n\n# train_data[\"family\"] = train_data[[\"SibSp\", \"Parch\"]].apply(has_family, axis=1)\n# train_data[\"family\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n# test_data.drop([\"SibSp\", \"Parch\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()[train_data.isnull().sum()>0]\ntest_data.isnull().sum()[test_data.isnull().sum()>0]\ntest_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# X = train_data.drop(\"Survived\", axis=1)\n# y = train_data[\"Survived\"]\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n\n# X_train = X\n# y_train = y\n\n# X_test = X\n# y_test = y\n\n# model = RandomForestClassifier(random_state = 1)\n# model.fit(X_train, y_train)\n# predictions = model.predict(X_test)\n\n# acc_random_forest = round(model.score(X_train, y_train) * 100, 2)\n# print(\"train\", acc_random_forest)\n# acc_random_forest = round(model.score(X_test, y_test) * 100, 2)\n# print(\"test \", acc_random_forest)\n\n# print(classification_report(y_test, predictions))\n# print(confusion_matrix(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\nxtrain = train_data.drop(\"Survived\",axis=1)\nytrain = train_data['Survived']\nxtest = test_data.drop(\"Survived\", axis=1)\n\nsvc = make_pipeline(StandardScaler(),SVC(random_state=1))\nr = [0.0001,0.001,0.1,1,10,50,100]\nPSVM = [{'svc__C':r, 'svc__kernel':['linear']},\n      {'svc__C':r, 'svc__gamma':r, 'svc__kernel':['rbf']}]\nGSSVM = GridSearchCV(estimator=svc, param_grid=PSVM, scoring='accuracy', cv=2)\nscores_svm = cross_val_score(GSSVM, xtrain.astype(float), ytrain,scoring='accuracy', cv=5)\nmodel = GSSVM.fit(xtrain, ytrain)\nnp.mean(scores_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test_data.drop(\"Survived\", axis=1))\n\ntest_dataID = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\noutput = pd.DataFrame({'PassengerId': test_dataID.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
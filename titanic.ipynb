{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1614,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/gender_submission.csv\n/kaggle/input/titanic/test.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":1615,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def put_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 19\n        else:\n            return 24\n    else:\n        return Age","execution_count":1616,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class1male = int(train_data[(train_data[\"Pclass\"]==1) & (train_data[\"Sex\"]==\"male\")][\"Age\"].mean())\nclass2male = int(train_data[(train_data[\"Pclass\"]==2) & (train_data[\"Sex\"]==\"male\")][\"Age\"].mean())\nclass3male = int(train_data[(train_data[\"Pclass\"]==3) & (train_data[\"Sex\"]==\"male\")][\"Age\"].mean())\n\nclass1female = int(train_data[(train_data[\"Pclass\"]==1) & (train_data[\"Sex\"]==\"female\")][\"Age\"].mean())\nclass2female = int(train_data[(train_data[\"Pclass\"]==2) & (train_data[\"Sex\"]==\"female\")][\"Age\"].mean())\nclass3female = int(train_data[(train_data[\"Pclass\"]==3) & (train_data[\"Sex\"]==\"female\")][\"Age\"].mean())\ndef set_age(cols):\n    pclass = cols[0]\n    sex = cols[1]\n    age = cols[2]\n    if pd.isnull(age):\n        if pclass == 1:\n            if sex == \"male\":\n                return class1male\n            else:\n                return class1female\n        elif pclass == 2:\n            if sex == \"male\":\n                return class2male\n            else:\n                return class2female\n        else:\n            if sex == \"male\":\n                return class3male\n            else:\n                return class3female\n    else:\n        return age","execution_count":1617,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data[\"Age\"] = train_data[[\"Pclass\", \"Sex\", \"Age\"]].apply(set_age, axis=1)\n# test_data[\"Age\"] = test_data[[\"Pclass\", \"Sex\", \"Age\"]].apply(set_age, axis=1)\n\ntrain_data[\"Age\"] = train_data[[\"Age\", \"Pclass\"]].apply(put_age, axis=1)\ntest_data[\"Age\"] = test_data[[\"Age\", \"Pclass\"]].apply(put_age, axis=1)","execution_count":1618,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Cabin\", axis=1, inplace=True)\ntest_data.drop(\"Cabin\", axis=1, inplace=True)","execution_count":1619,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"Embarked\"] = train_data[\"Embarked\"].apply(lambda x: \"S\" if pd.isnull(x) else x)","execution_count":1620,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fare = int(train_data[(train_data[\"Pclass\"]==3) & (train_data[\"Sex\"]==\"male\")][\"Fare\"].mean())\ntest_data[\"Fare\"] = test_data[\"Fare\"].apply(lambda x: fare if pd.isnull(x) else x)","execution_count":1621,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Title'] = train_data[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntrain_data[\"Title\"].value_counts()\ntest_data['Title'] = test_data[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_data[\"Title\"].value_counts()","execution_count":1622,"outputs":[{"output_type":"execute_result","execution_count":1622,"data":{"text/plain":"Mr        240\nMiss       78\nMrs        72\nMaster     21\nCol         2\nRev         2\nMs          1\nDona        1\nDr          1\nName: Title, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Ms', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\ntrain_data['Title'] = train_data['Title'].replace('Major', 'Military')\ntrain_data['Title'] = train_data['Title'].replace('Col', 'Military')\ntrain_data['Title'] = train_data['Title'].replace('Capt', 'Military')\ntrain_data['Title'] = train_data['Title'].replace('Lady', 'Royal')\ntrain_data['Title'] = train_data['Title'].replace('Don', 'Royal')\ntrain_data['Title'] = train_data['Title'].replace('Countess', 'Royal')\ntrain_data['Title'] = train_data['Title'].replace('Jonkheer', 'Royal')\ntrain_data['Title'] = train_data['Title'].replace('Sir', 'Royal')\ntrain_data['Title'] = train_data['Title'].replace('Dona', 'Royal')\ntrain_data[\"Title\"].value_counts()\n\ntest_data['Title'] = test_data['Title'].replace('Mlle', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Ms', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Mme', 'Mrs')\ntest_data['Title'] = test_data['Title'].replace('Major', 'Military')\ntest_data['Title'] = test_data['Title'].replace('Col', 'Military')\ntest_data['Title'] = test_data['Title'].replace('Capt', 'Military')\ntest_data['Title'] = test_data['Title'].replace('Lady', 'Royal')\ntest_data['Title'] = test_data['Title'].replace('Don', 'Royal')\ntest_data['Title'] = test_data['Title'].replace('Countess', 'Royal')\ntest_data['Title'] = test_data['Title'].replace('Jonkheer', 'Royal')\ntest_data['Title'] = test_data['Title'].replace('Sir', 'Royal')\ntest_data['Title'] = test_data['Title'].replace('Dona', 'Royal')\ntest_data[\"Title\"].value_counts()","execution_count":1623,"outputs":[{"output_type":"execute_result","execution_count":1623,"data":{"text/plain":"Mr          240\nMiss         79\nMrs          72\nMaster       21\nMilitary      2\nRev           2\nDr            1\nRoyal         1\nName: Title, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic=pd.concat([train_data, test_data], sort=False)\nlen_train=train_data.shape[0]\ntitanic['LastName'] = titanic[\"Name\"].apply(lambda x: x.split(',')[0].strip())","execution_count":1624,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sex = pd.get_dummies(train_data[\"Sex\"], drop_first=True)\n# embark = pd.get_dummies(train_data[\"Embarked\"], drop_first=True)\n# pclass = pd.get_dummies(train_data[\"Pclass\"], drop_first=True)\n# title = pd.get_dummies(train_data[\"Title\"], drop_first=True)\n# last = pd.get_dummies(train_data[\"LastName\"], drop_first=True)\n# train_data = pd.concat([train_data, sex, embark, pclass, title, last], axis=1)\n\n# train_data.drop([\"PassengerId\", \"Sex\", \"Embarked\", \"Name\", \"Ticket\", \"Pclass\", \"Title\", \"LastName\"], axis=1, inplace=True)\n\n# sex = pd.get_dummies(test_data[\"Sex\"], drop_first=True)\n# embark = pd.get_dummies(test_data[\"Embarked\"], drop_first=True)\n# pclass = pd.get_dummies(test_data[\"Pclass\"], drop_first=True)\n# title = pd.get_dummies(test_data[\"Title\"], drop_first=True)\n# last = pd.get_dummies(test_data[\"LastName\"], drop_first=True)\n# test_data = pd.concat([test_data, sex, embark, pclass, title, last], axis=1)\n\n# test_data.drop([\"PassengerId\", \"Sex\", \"Embarked\", \"Name\", \"Ticket\", \"Pclass\", \"Title\", \"LastName\"], axis=1, inplace=True)\n\nsex = pd.get_dummies(titanic[\"Sex\"], drop_first=True)\nembark = pd.get_dummies(titanic[\"Embarked\"], drop_first=True)\npclass = pd.get_dummies(titanic[\"Pclass\"], drop_first=True)\ntitle = pd.get_dummies(titanic[\"Title\"], drop_first=True)\nlast = pd.get_dummies(titanic[\"LastName\"], drop_first=True)\ntitanic = pd.concat([titanic, sex, embark, pclass, title, last], axis=1)\n\ntitanic.drop([\"PassengerId\", \"Sex\", \"Embarked\", \"Name\", \"Ticket\", \"Pclass\", \"Title\", \"LastName\"], axis=1, inplace=True)","execution_count":1625,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = titanic[:len_train]\ntest_data = titanic[len_train:]\ntrain_data[\"Survived\"] = train_data[\"Survived\"].astype(\"int\")","execution_count":1626,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def has_family(data):\n#     if data[0] > 0 or data[1] > 0:\n#         return 1\n#     else:\n#         return 0\n\n# train_data[\"family\"] = train_data[[\"SibSp\", \"Parch\"]].apply(has_family, axis=1)\n# train_data[\"family\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n# test_data.drop([\"SibSp\", \"Parch\"], axis=1, inplace=True)","execution_count":1627,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()[train_data.isnull().sum()>0]\ntest_data.isnull().sum()[test_data.isnull().sum()>0]\ntest_data","execution_count":1628,"outputs":[{"output_type":"execute_result","execution_count":1628,"data":{"text/plain":"     Survived   Age  SibSp  Parch      Fare  male  Q  S  2  3  ...  Zabour  \\\n0         NaN  34.5      0      0    7.8292     1  1  0  0  1  ...       0   \n1         NaN  47.0      1      0    7.0000     0  0  1  0  1  ...       0   \n2         NaN  62.0      0      0    9.6875     1  1  0  1  0  ...       0   \n3         NaN  27.0      0      0    8.6625     1  0  1  0  1  ...       0   \n4         NaN  22.0      1      1   12.2875     0  0  1  0  1  ...       0   \n..        ...   ...    ...    ...       ...   ... .. .. .. ..  ...     ...   \n413       NaN  24.0      0      0    8.0500     1  0  1  0  1  ...       0   \n414       NaN  39.0      0      0  108.9000     0  0  0  0  0  ...       0   \n415       NaN  38.5      0      0    7.2500     1  0  1  0  1  ...       0   \n416       NaN  24.0      0      0    8.0500     1  0  1  0  1  ...       0   \n417       NaN  24.0      1      1   22.3583     1  0  0  0  1  ...       0   \n\n     Zakarian  Zimmerman  de Brito  de Messemaeker  de Mulder  de Pelsmaeker  \\\n0           0          0         0               0          0              0   \n1           0          0         0               0          0              0   \n2           0          0         0               0          0              0   \n3           0          0         0               0          0              0   \n4           0          0         0               0          0              0   \n..        ...        ...       ...             ...        ...            ...   \n413         0          0         0               0          0              0   \n414         0          0         0               0          0              0   \n415         0          0         0               0          0              0   \n416         0          0         0               0          0              0   \n417         0          0         0               0          0              0   \n\n     del Carlo  van Billiard  van Melkebeke  \n0            0             0              0  \n1            0             0              0  \n2            0             0              0  \n3            0             0              0  \n4            0             0              0  \n..         ...           ...            ...  \n413          0             0              0  \n414          0             0              0  \n415          0             0              0  \n416          0             0              0  \n417          0             0              0  \n\n[418 rows x 891 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>male</th>\n      <th>Q</th>\n      <th>S</th>\n      <th>2</th>\n      <th>3</th>\n      <th>...</th>\n      <th>Zabour</th>\n      <th>Zakarian</th>\n      <th>Zimmerman</th>\n      <th>de Brito</th>\n      <th>de Messemaeker</th>\n      <th>de Mulder</th>\n      <th>de Pelsmaeker</th>\n      <th>del Carlo</th>\n      <th>van Billiard</th>\n      <th>van Melkebeke</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.8292</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.0000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9.6875</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.6625</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>12.2875</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>NaN</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108.9000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>NaN</td>\n      <td>38.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22.3583</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 891 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# X = train_data.drop(\"Survived\", axis=1)\n# y = train_data[\"Survived\"]\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n\n# X_train = X\n# y_train = y\n\n# X_test = X\n# y_test = y\n\n# model = RandomForestClassifier(random_state = 1)\n# model.fit(X_train, y_train)\n# predictions = model.predict(X_test)\n\n# acc_random_forest = round(model.score(X_train, y_train) * 100, 2)\n# print(\"train\", acc_random_forest)\n# acc_random_forest = round(model.score(X_test, y_test) * 100, 2)\n# print(\"test \", acc_random_forest)\n\n# print(classification_report(y_test, predictions))\n# print(confusion_matrix(y_test, predictions))","execution_count":1629,"outputs":[{"output_type":"stream","text":"train 99.89\ntest  99.89\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       549\n           1       1.00      1.00      1.00       342\n\n    accuracy                           1.00       891\n   macro avg       1.00      1.00      1.00       891\nweighted avg       1.00      1.00      1.00       891\n\n[[548   1]\n [  0 342]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\nxtrain = train_data.drop(\"Survived\",axis=1)\nytrain = train_data['Survived']\nxtest = test_data.drop(\"Survived\", axis=1)\n\nsvc = make_pipeline(StandardScaler(),SVC(random_state=1))\nr = [0.0001,0.001,0.1,1,10,50,100]\nPSVM = [{'svc__C':r, 'svc__kernel':['linear']},\n      {'svc__C':r, 'svc__gamma':r, 'svc__kernel':['rbf']}]\nGSSVM = GridSearchCV(estimator=svc, param_grid=PSVM, scoring='accuracy', cv=2)\nscores_svm = cross_val_score(GSSVM, xtrain.astype(float), ytrain,scoring='accuracy', cv=5)\nmodel = GSSVM.fit(xtrain, ytrain)\nnp.mean(scores_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test_data.drop(\"Survived\", axis=1))\n\ntest_dataID = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\noutput = pd.DataFrame({'PassengerId': test_dataID.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":1630,"outputs":[{"output_type":"stream","text":"Your submission was successfully saved!\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}